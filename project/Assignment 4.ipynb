{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481b9274",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c166c2",
   "metadata": {},
   "source": [
    "## AI usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc00a8",
   "metadata": {},
   "source": [
    "## Log\n",
    "\n",
    "Working on this assignment I am working first on requirements for the Jupyter Notebook and subsequently updating the Streamlit app. \n",
    "\n",
    "I really enjoyed working with the same import structure as in Assignment 2, with the Elhub API. However, I realized that the name I chose for the tables (`elhub_api`) in Cassandra and MongoDB weren't descriptive enough, as we now are using two tables from the same API. I was also unsure of whether the new production data from 2022-2024 should be strictly appended to the old tables or if I could remake the tables with data 2021-2024. Manipulating data with Spark and inserting into Cassandra and MongoDB was otherwise fine, mostly following the same structure from Assignment 2.\n",
    "\n",
    "Updates for the Streamlit app have felt difficult as I haven't caught up with the progress in the lectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf5847",
   "metadata": {},
   "source": [
    "## Links \n",
    "\n",
    "- Github: https://github.com/Satheris/IND320_SMAA\n",
    "- Streamlit app: https://ind320smaa-2eg32uba6uhmrknkwtxzar.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451caf4",
   "metadata": {},
   "source": [
    "## Coding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56641cee",
   "metadata": {},
   "source": [
    "### Imports and system variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380122f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import streamlit as st\n",
    "import pymongo\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql import SparkSession\n",
    "from pyjstat import pyjstat\n",
    "import requests\n",
    "import json\n",
    "import plotly.express as px\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook+pdf+plotly_mimetype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for PySpark (system and version dependent!) \n",
    "# if not already set persistently (e.g., in .bashrc or .bash_profile or Windows environment variables)\n",
    "import os\n",
    "# Set the Java home path to the one you are using ((un)comment and edit as needed):\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Java\\jre1.8.0_471\"\n",
    "\n",
    "# If you are using environments in Python, you can set the environment variables like the alternative below.\n",
    "# The default Python environment is used if the variables are set to \"python\" (edit if needed):\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\" # or similar to \"/Users/kristian/miniforge3/envs/tf_M1/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\" # or similar to \"/Users/kristian/miniforge3/envs/tf_M1/bin/python\"\n",
    "\n",
    "# On Windows you need to specify where the Hadoop drivers are located (uncomment and edit if needed):\n",
    "os.environ[\"HADOOP_HOME\"] = r\"C:\\Users\\saraa\\Documents\\winutils\\hadoop-3.3.1\"\n",
    "\n",
    "# Set the Hadoop version to the one you are using, e.g., none:\n",
    "os.environ[\"PYSPARK_HADOOP_VERSION\"] = \"without\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07edf8",
   "metadata": {},
   "source": [
    "### Cassandra and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING\tcassandra.cluster:cluster.py:__init__()- Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['localhost'], lbp = None)\n",
      "WARNING\tcassandra.cluster:cluster.py:protocol_downgrade()- Downgrading core protocol version from 66 to 65 for ::1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING\tcassandra.cluster:cluster.py:protocol_downgrade()- Downgrading core protocol version from 65 to 5 for ::1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.cluster:cluster.py:_reconnect_internal()- [control connection] Error connecting to ::1:9042:\n",
      " Traceback (most recent call last):\n",
      "   File \"c:\\Users\\saraa\\anaconda3\\envs\\IND320_SMAA\\Lib\\site-packages\\cassandra\\cluster.py\", line 3577, in _reconnect_internal\n",
      "    return self._try_connect(host)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "   File \"c:\\Users\\saraa\\anaconda3\\envs\\IND320_SMAA\\Lib\\site-packages\\cassandra\\cluster.py\", line 3599, in _try_connect\n",
      "    connection = self._cluster.connection_factory(host.endpoint, is_control_connection=True)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "   File \"c:\\Users\\saraa\\anaconda3\\envs\\IND320_SMAA\\Lib\\site-packages\\cassandra\\cluster.py\", line 1670, in connection_factory\n",
      "    return self.connection_class.factory(endpoint, self.connect_timeout, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "   File \"c:\\Users\\saraa\\anaconda3\\envs\\IND320_SMAA\\Lib\\site-packages\\cassandra\\connection.py\", line 852, in factory\n",
      "    raise conn.last_error\n",
      " cassandra.connection.ConnectionShutdown: Connection to ::1:9042 was closed\n",
      "\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 2.14 seconds: Connection to ::1:9042 was closed\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 6.8 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 18.24 seconds: [Errno None] Tried connecting to [('::1', 9042, 0, 0)]. Last error: timed out\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 33.92 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 144.64 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 578.56 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 582.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 570.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 510.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 510.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 546.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno None] Tried connecting to [('::1', 9042, 0, 0)]. Last error: timed out\n",
      "WARNING\tThread(ThreadPoolExecutor-1_0) cassandra.pool:pool.py:on_exception()- Error attempting to reconnect to ::1:9042, scheduling retry in 600.0 seconds: [Errno 10061] Tried connecting to [('::1', 9042, 0, 0)]. Last error: Kan ikke koble til fordi målmaskinen avslo tilkobling\n"
     ]
    }
   ],
   "source": [
    "# Connecting to Cassandra\n",
    "# Run local Docker container first\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0a94c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x25f0957c510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up new keyspace\n",
    "#                                              name of keyspace                        replication strategy           replication factor\n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS ind320_keyspace WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "\n",
    "# Create a new table\n",
    "session.set_keyspace('ind320_keyspace')\n",
    "# session.execute(\"DROP TABLE IF EXISTS ind320_keyspace.elhub_api;\") # Starting from scratch every time\n",
    "session.execute(\"DROP TABLE IF EXISTS ind320_keyspace.elhub_production;\") # Starting from scratch every time\n",
    "session.execute(\"DROP TABLE IF EXISTS ind320_keyspace.elhub_consumption;\") # Starting from scratch every time\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS elhub_production \\\n",
    "                (ind int PRIMARY KEY, startTime text, endTime text, lastUpdatedTime text, \\\n",
    "                productionGroup text, quantityKwh float, \\\n",
    "                priceArea text);\")\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS elhub_consumption \\\n",
    "                (ind int PRIMARY KEY, startTime text, endTime text, lastUpdatedTime text, \\\n",
    "                consumptionGroup text, quantityKwh float, \\\n",
    "                priceArea text, meteringPointCount int)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f9cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SparkCassandraApp').\\\n",
    "    config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.5.1').\\\n",
    "    config('spark.cassandra.connection.host', 'localhost').\\\n",
    "    config('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions').\\\n",
    "    config('spark.sql.catalog.mycatalog', 'com.datastax.spark.connector.datasource.CassandraCatalog').\\\n",
    "    config('spark.cassandra.connection.port', '9042').\\\n",
    "    config('spark.driver.host', 'localhost').\\\n",
    "    config('spark.driver.bindAddress', '127.0.0.1').\\\n",
    "    config('spark.sql.adaptive.enabled', 'true').\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d90f9",
   "metadata": {},
   "source": [
    "#### Testing that the connection works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4c4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "|ind| company|  model|\n",
      "+---+--------+-------+\n",
      "|460|    Ford|Transit|\n",
      "|459|    Ford| Escort|\n",
      "|  3|Polestar|      3|\n",
      "|  1|   Tesla|Model S|\n",
      "|  2|   Tesla|Model 3|\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .load() is used to load data from Cassandra table as a Spark DataFrame\n",
    "spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").load().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376f107",
   "metadata": {},
   "source": [
    "### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1317cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "def init_connection():\n",
    "    return pymongo.MongoClient(st.secrets[\"mongo\"][\"uri\"])\n",
    "\n",
    "client = init_connection()\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe80a4c",
   "metadata": {},
   "source": [
    "### Elhub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d5415",
   "metadata": {},
   "source": [
    "#### Production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1405ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created DataFrame with 872953 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ind",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lastUpdatedTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "priceArea",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "productionGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "quantityKwh",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "startTime",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e36126a7-d8d4-4741-80a5-44e52b873b0d",
       "rows": [
        [
         "0",
         "0",
         "2021-01-01T01:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "NO1",
         "hydro",
         "2507716.8",
         "2021-01-01T00:00:00+01:00"
        ],
        [
         "1",
         "1",
         "2021-01-01T02:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "NO1",
         "hydro",
         "2494728.0",
         "2021-01-01T01:00:00+01:00"
        ],
        [
         "2",
         "2",
         "2021-01-01T03:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "NO1",
         "hydro",
         "2486777.5",
         "2021-01-01T02:00:00+01:00"
        ],
        [
         "3",
         "3",
         "2021-01-01T04:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "NO1",
         "hydro",
         "2461176.0",
         "2021-01-01T03:00:00+01:00"
        ],
        [
         "4",
         "4",
         "2021-01-01T05:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "NO1",
         "hydro",
         "2466969.2",
         "2021-01-01T04:00:00+01:00"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2507716.8</td>\n",
       "      <td>2021-01-01T00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2494728.0</td>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2486777.5</td>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2461176.0</td>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-01T05:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2466969.2</td>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind                    endTime            lastUpdatedTime priceArea  \\\n",
       "0    0  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "1    1  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "2    2  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "3    3  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "4    4  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "\n",
       "  productionGroup  quantityKwh                  startTime  \n",
       "0           hydro    2507716.8  2021-01-01T00:00:00+01:00  \n",
       "1           hydro    2494728.0  2021-01-01T01:00:00+01:00  \n",
       "2           hydro    2486777.5  2021-01-01T02:00:00+01:00  \n",
       "3           hydro    2461176.0  2021-01-01T03:00:00+01:00  \n",
       "4           hydro    2466969.2  2021-01-01T04:00:00+01:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initating lists for traversing the URL\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for i, year in enumerate(years[:-1]):\n",
    "    for j, month in enumerate(months):\n",
    "\n",
    "        # catching last month with adapted URL for end time\n",
    "        if month == months[-1]:\n",
    "            URL = 'https://api.elhub.no/energy-data/v0/price-areas?dataset=PRODUCTION_PER_GROUP_MBA_HOUR&'\\\n",
    "                f'startDate={year}-{month}-01T00:00:00%2B02:00&endDate={years[i+1]}-{months[0]}-01T00:00:00%2B02:00'\n",
    "            \n",
    "        # all other months follow the same structure\n",
    "        else: \n",
    "            URL = 'https://api.elhub.no/energy-data/v0/price-areas?dataset=PRODUCTION_PER_GROUP_MBA_HOUR&'\\\n",
    "                f'startDate={year}-{month}-01T00:00:00%2B02:00&endDate={year}-{months[j+1]}-01T00:00:00%2B02:00'\n",
    "\n",
    "        payload = { \n",
    "            \"query\": [], \n",
    "            \"response\": { \"format\": \"json-stat2\" } }\n",
    "\n",
    "        response = requests.get(URL, json=payload)\n",
    "        \n",
    "        # print(f\"Y:{year}, m:{month}, Status Code: {response.status_code}\")\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        for area in data['data']:\n",
    "            records = area['attributes']['productionPerGroupMbaHour']\n",
    "            for record in records:\n",
    "                record['priceArea'] = area['attributes']['name']\n",
    "                all_records.append(record)\n",
    "\n",
    "elhub_production = pd.DataFrame(all_records)\n",
    "elhub_production.index.name = 'ind'\n",
    "elhub_production = elhub_production.reset_index()\n",
    "\n",
    "print(f\"\\nCreated DataFrame with {len(elhub_production)} rows\")\n",
    "elhub_production.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11902591",
   "metadata": {},
   "source": [
    "#### Consumption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56060b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created DataFrame with 876600 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ind",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "consumptionGroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "endTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lastUpdatedTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meteringPointCount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "priceArea",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "quantityKwh",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "startTime",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9cfc6f58-f418-4d2d-85d7-2177745ca411",
       "rows": [
        [
         "0",
         "0",
         "cabin",
         "2021-01-01T01:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "100607",
         "NO1",
         "177071.56",
         "2021-01-01T00:00:00+01:00"
        ],
        [
         "1",
         "1",
         "cabin",
         "2021-01-01T02:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "100607",
         "NO1",
         "171335.12",
         "2021-01-01T01:00:00+01:00"
        ],
        [
         "2",
         "2",
         "cabin",
         "2021-01-01T03:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "100607",
         "NO1",
         "164912.02",
         "2021-01-01T02:00:00+01:00"
        ],
        [
         "3",
         "3",
         "cabin",
         "2021-01-01T04:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "100607",
         "NO1",
         "160265.77",
         "2021-01-01T03:00:00+01:00"
        ],
        [
         "4",
         "4",
         "cabin",
         "2021-01-01T05:00:00+01:00",
         "2024-12-20T10:35:40+01:00",
         "100607",
         "NO1",
         "159828.69",
         "2021-01-01T04:00:00+01:00"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>consumptionGroup</th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>meteringPointCount</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cabin</td>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>100607</td>\n",
       "      <td>NO1</td>\n",
       "      <td>177071.56</td>\n",
       "      <td>2021-01-01T00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cabin</td>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>100607</td>\n",
       "      <td>NO1</td>\n",
       "      <td>171335.12</td>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cabin</td>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>100607</td>\n",
       "      <td>NO1</td>\n",
       "      <td>164912.02</td>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cabin</td>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>100607</td>\n",
       "      <td>NO1</td>\n",
       "      <td>160265.77</td>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cabin</td>\n",
       "      <td>2021-01-01T05:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>100607</td>\n",
       "      <td>NO1</td>\n",
       "      <td>159828.69</td>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind consumptionGroup                    endTime            lastUpdatedTime  \\\n",
       "0    0            cabin  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00   \n",
       "1    1            cabin  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00   \n",
       "2    2            cabin  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00   \n",
       "3    3            cabin  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00   \n",
       "4    4            cabin  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00   \n",
       "\n",
       "   meteringPointCount priceArea  quantityKwh                  startTime  \n",
       "0              100607       NO1    177071.56  2021-01-01T00:00:00+01:00  \n",
       "1              100607       NO1    171335.12  2021-01-01T01:00:00+01:00  \n",
       "2              100607       NO1    164912.02  2021-01-01T02:00:00+01:00  \n",
       "3              100607       NO1    160265.77  2021-01-01T03:00:00+01:00  \n",
       "4              100607       NO1    159828.69  2021-01-01T04:00:00+01:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initating lists for traversing the URL\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for i, year in enumerate(years[:-1]):\n",
    "    for j, month in enumerate(months):\n",
    "        \n",
    "        # catching last month with adapted URL for end time\n",
    "        if month == months[-1]:\n",
    "            URL = 'https://api.elhub.no/energy-data/v0/price-areas?dataset=CONSUMPTION_PER_GROUP_MBA_HOUR&'\\\n",
    "                f'startDate={year}-{month}-01T00:00:00%2B02:00&endDate={years[i+1]}-{months[0]}-01T00:00:00%2B02:00'\n",
    "        \n",
    "        # all other months follow the same structure\n",
    "        else: \n",
    "            URL = 'https://api.elhub.no/energy-data/v0/price-areas?dataset=CONSUMPTION_PER_GROUP_MBA_HOUR&'\\\n",
    "                f'startDate={year}-{month}-01T00:00:00%2B02:00&endDate={year}-{months[j+1]}-01T00:00:00%2B02:00'\n",
    "\n",
    "        payload = { \n",
    "            \"query\": [], \n",
    "            \"response\": { \"format\": \"json-stat2\" } }\n",
    "\n",
    "        response = requests.get(URL, json=payload)\n",
    "        \n",
    "        # print(f\"Y:{year}, m:{month}, Status Code: {response.status_code}\")\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        for area in data['data']:\n",
    "            records = area['attributes']['consumptionPerGroupMbaHour']\n",
    "            for record in records:\n",
    "                record['priceArea'] = area['attributes']['name']\n",
    "                all_records.append(record)\n",
    "\n",
    "elhub_consumption = pd.DataFrame(all_records)\n",
    "elhub_consumption.index.name = 'ind'\n",
    "elhub_consumption = elhub_consumption.reset_index()\n",
    "\n",
    "print(f\"\\nCreated DataFrame with {len(elhub_consumption)} rows\")\n",
    "elhub_consumption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32852405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved elhub_production to Cassandra\n",
      "Saved elhub_consumption to Cassandra\n"
     ]
    }
   ],
   "source": [
    "# I found that the columns in the Cassandra table was constructed with lowercase letters.\n",
    "# Therefore, I need to convert the column names to lowercase before writing to Cassandra\n",
    "\n",
    "str_list = ['elhub_production', 'elhub_consumption']\n",
    "\n",
    "for i, table in enumerate([elhub_production, elhub_consumption]):\n",
    "    name_dict = {}\n",
    "    for capitalname in (table.columns):\n",
    "        name_dict[capitalname] = capitalname.lower()\n",
    "    \n",
    "    table = table.rename(columns=name_dict)\n",
    "\n",
    "    # Convert the Pandas DataFrame to Spark DataFrame and save it to Cassandra (append mode)\n",
    "    spark.createDataFrame(table).write.format('org.apache.spark.sql.cassandra')\\\n",
    "    .options(table=str_list[i], keyspace='ind320_keyspace').mode('append').save()\n",
    "\n",
    "    print(f'Saved {str_list[i]} to Cassandra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a540c0",
   "metadata": {},
   "source": [
    "### Saving dfs to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44431732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted elhub_production to MongoDB\n",
      "Successfully inserted elhub_consumption to MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Selecting a database and a collection\n",
    "database = client['project']\n",
    "\n",
    "for table in str_list:\n",
    "    collection = database[table]\n",
    "    collection.delete_many({}) # starting fresh\n",
    "\n",
    "    spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=table, keyspace=\"ind320_keyspace\").load()\\\n",
    "    .createOrReplaceTempView(f\"{table}_view\")\n",
    "\n",
    "    df_spark = spark.sql(f\"SELECT priceArea, {table.split('_')[1]}Group, startTime, quantityKwh FROM {table}_view\")\n",
    "\n",
    "    # Convert DataFrame to JSON and dumping to MongoDB\n",
    "    df_pd = df_spark.toPandas()\n",
    "    json_data = df_pd.to_json(orient='records')\n",
    "\n",
    "    documents = json.loads(json_data)\n",
    "    try: \n",
    "        collection.insert_many(documents)\n",
    "        print(f'Successfully inserted {table} to MongoDB')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e10e9",
   "metadata": {},
   "source": [
    "### Stopping Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "440971e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session terminated successfully\n"
     ]
    }
   ],
   "source": [
    "# Stop Spark session\n",
    "try:\n",
    "    spark.stop()\n",
    "    print('Spark session terminated successfully')\n",
    "except ConnectionRefusedError:\n",
    "    print(\"Spark session already stopped.\")\n",
    "except NameError:\n",
    "    print('Spark session is not defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83cc53",
   "metadata": {},
   "source": [
    "### Testing for Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9cbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IND320_SMAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
