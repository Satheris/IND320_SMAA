{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9606477",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d72be5",
   "metadata": {},
   "source": [
    "## AI usage \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9c323",
   "metadata": {},
   "source": [
    "## Log \n",
    "\n",
    "For this assignment I will try to work more systematic than the last. I will focus on finishing all the elements for the notebook first, and work on the streamlit app afterwards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299533c",
   "metadata": {},
   "source": [
    "## Links \n",
    "\n",
    "- Github: https://github.com/Satheris/IND320_SMAA\n",
    "- Streamlit app: https://ind320smaa-2eg32uba6uhmrknkwtxzar.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530005e",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d9397",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5b8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa36443",
   "metadata": {},
   "source": [
    "### Cassandra and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbdc9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f781e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594220f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a89b09",
   "metadata": {},
   "source": [
    "### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f4a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b66397",
   "metadata": {},
   "source": [
    "# General\n",
    "\n",
    "\n",
    "A Streamlit app running from https://[yourproject].streamlit.app/.\n",
    "This is an online version of the project, accessing data that has been exported to CSV format and accessing your MongoDB database for additional data.\n",
    "The code, hosted at GitHub, must include relevant comments from the Jupyter Notebook and further comments regarding Streamlit usage.\n",
    "\n",
    "\n",
    "## Tasks\n",
    "### Accounts and repositories\n",
    "Reuse your account, repository and Streamlit app from the previous part of the project work.\n",
    "Until peer review and feedback have been completed, push to a temporary GitHub branch for later merging.\n",
    "\n",
    "### Local database: Cassandra\n",
    "If not already done, set up Cassandra and Spark as described in the book.\n",
    "Test that your Spark-Cassandra connection works.\n",
    "The Cassandra database will be accessed from the Jupyter Notebook and used to store data from the API mentioned later. \n",
    "\n",
    "### Remote database: MongoDB\n",
    "If not already done, prepare a MongoDB account at mongodb.com.\n",
    "Test that you can manipulate data from Python.\n",
    "The MongoDB database will store data that has been trimmed/curated/prepared through the Jupyter Notebook and Spark filtering.\n",
    "These data will be accessed directly from the Streamlit app.\n",
    "\n",
    "### API\n",
    "Familiarise yourself with the API connection at https://api.elhub.noLenker til en ekstern side.\n",
    "\n",
    "Observe how time is encoded and how transitions between summer and winter time are handled.\n",
    "Be aware of the time period limitations for each API request and how this differs between datasets.\n",
    "\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "#### Standard requirements\n",
    "\n",
    "Must include a brief description of AI usage.\n",
    "\n",
    "Must include a 300-500-word log describing the compulsory work (including both Jupyter Notebook and Streamlit experience).\n",
    "\n",
    "Must include links to your public GitHub repository and Streamlit app (see below) for the compulsory work.\n",
    "\n",
    "Document headings should be clear and usable for navigation during development.\n",
    "\n",
    "All code blocks must include enough comments to be understandable and reproducible if someone inherits your project.\n",
    "\n",
    "All code blocks must be run before an export to PDF so the messages and plots are shown. In addition, add the .ipynb file to the GitHub repository where you have your Streamlit project.\n",
    "\n",
    "\n",
    "#### Tasks for assignment 2\n",
    "Use the Elhub API to retrieve hourly production data for all price areas using PRODUCTION_PER_GROUP_MBA_HOUR for all days and hours of the year 2021.\n",
    "\n",
    "Extract only the list in productionPerGroupMbaHour, convert to a DataFrame, and insert the data into Cassandra using Spark.\n",
    "\n",
    "Use Spark to extract the columns priceArea, productionGroup, startTime, and quantityKwh from Cassandra.\n",
    "\n",
    "Create the following plots:\n",
    "- A pie chart for the total production of the year from a chosen price area, where each piece of the pie is one of the production groups.\n",
    "- A line plot for the first month of the year for a chosen price area. Make separate lines for each production group.\n",
    "\n",
    "Insert the Spark-extracted data into your MongoDB.\n",
    "\n",
    "Remember to fill in the log and AI mentioned in the General section above.\n",
    "\n",
    "### Streamlit app\n",
    "Establish a connection with your MongoDB database. When running this at streamlit.io, remember to copy your secrets to the webpage instead of exposing them on GitHub.\n",
    "\n",
    "On page four, split the view into two columns using st.columns.\n",
    "\n",
    "- On the left side, use radio buttons (st.radio) to select a price area and display a pie chart like in the Jupyter Notebook\n",
    "\n",
    "- On the right side, use pills (st.pills) to select which production groups to include and a selection element of your choice to select a month. Combine the price area, production group(s) and month, and display a line plot like in the Jupyter Notebook (but for any month).\n",
    "\n",
    "- Below the columns, insert an expander (st.expander) where you briefly document the source of the data shown on the page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IND320_SMAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
